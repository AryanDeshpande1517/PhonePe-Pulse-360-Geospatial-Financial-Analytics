{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "042e6c5c",
   "metadata": {},
   "source": [
    "# üìä PhonePe Pulse Data Extraction Pipeline\n",
    "\n",
    "This notebook implements a structured ETL pipeline for the **PhonePe Pulse Open Data Repository**.\n",
    "\n",
    "The dataset contains 5000+ deeply nested JSON files organized by:\n",
    "\n",
    "- State\n",
    "- Year\n",
    "- Quarter\n",
    "- Transaction Type\n",
    "- User Metrics\n",
    "- District-Level Data\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "This pipeline performs:\n",
    "\n",
    "1. Recursive directory traversal  \n",
    "2. JSON normalization  \n",
    "3. Transaction metric extraction  \n",
    "4. User metric extraction  \n",
    "5. District-level extraction  \n",
    "6. Data cleaning & standardization  \n",
    "7. CSV export for Power BI modeling  \n",
    "\n",
    "The final structured datasets are prepared for **Star Schema modeling in Power BI**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a01ca",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Define the base directory of the cloned PhonePe Pulse repository.\n",
    "\n",
    "Ensure that the `pulse` folder is located in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"pulse/data\")  # Update if your path differs\n",
    "\n",
    "if not BASE_DIR.exists():\n",
    "    print(\"‚ùå Base directory not found. Ensure you cloned the PhonePe Pulse repo correctly.\")\n",
    "else:\n",
    "    print(\"‚úÖ Base directory located successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b18df",
   "metadata": {},
   "source": [
    "## üîπ Phase 1: Aggregated Transaction Extraction\n",
    "\n",
    "This section extracts:\n",
    "\n",
    "- Transaction Type  \n",
    "- Transaction Count  \n",
    "- Transaction Amount  \n",
    "- State  \n",
    "- Year  \n",
    "- Quarter  \n",
    "\n",
    "Data is stored in nested directories under:\n",
    "\n",
    "`aggregated/transaction/country/india/state/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aggregated_transactions(base_dir):\n",
    "    path = base_dir / \"aggregated/transaction/country/india/state\"\n",
    "    data_list = []\n",
    "\n",
    "    if not path.exists():\n",
    "        print(f\"Path not found: {path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for state in os.listdir(path):\n",
    "        state_path = path / state\n",
    "\n",
    "        for year in os.listdir(state_path):\n",
    "            year_path = state_path / year\n",
    "\n",
    "            for file in os.listdir(year_path):\n",
    "                file_path = year_path / file\n",
    "\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                try:\n",
    "                    for item in data[\"data\"][\"transactionData\"]:\n",
    "                        data_list.append({\n",
    "                            \"State\": state,\n",
    "                            \"Year\": int(year),\n",
    "                            \"Quarter\": int(file.strip(\".json\")),\n",
    "                            \"Transaction_Type\": item[\"name\"],\n",
    "                            \"Transaction_Count\": item[\"paymentInstruments\"][0][\"count\"],\n",
    "                            \"Transaction_Amount\": item[\"paymentInstruments\"][0][\"amount\"]\n",
    "                        })\n",
    "                except (TypeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Extracting Aggregated Transactions...\")\n",
    "df_transactions = extract_aggregated_transactions(BASE_DIR)\n",
    "\n",
    "if not df_transactions.empty:\n",
    "    df_transactions.to_csv(\"phonepe_aggregated_transactions.csv\", index=False)\n",
    "    print(\"‚úÖ Saved as phonepe_aggregated_transactions.csv\")\n",
    "    print(f\"Rows Extracted: {len(df_transactions)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Extraction returned empty dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e62c8",
   "metadata": {},
   "source": [
    "## üîπ Phase 2: Aggregated User Data Extraction\n",
    "\n",
    "This section extracts:\n",
    "\n",
    "- Device Brand  \n",
    "- User Count  \n",
    "- Percentage Share  \n",
    "- State  \n",
    "- Year  \n",
    "- Quarter  \n",
    "\n",
    "Data source:\n",
    "\n",
    "`aggregated/user/country/india/state/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f0d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aggregated_users(base_dir):\n",
    "    path = base_dir / \"aggregated/user/country/india/state\"\n",
    "    user_list = []\n",
    "\n",
    "    if not path.exists():\n",
    "        print(f\"Path not found: {path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for state in os.listdir(path):\n",
    "        state_path = path / state\n",
    "\n",
    "        for year in os.listdir(state_path):\n",
    "            year_path = state_path / year\n",
    "\n",
    "            for file in os.listdir(year_path):\n",
    "                file_path = year_path / file\n",
    "\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                try:\n",
    "                    if data[\"data\"][\"usersByDevice\"]:\n",
    "                        for brand_data in data[\"data\"][\"usersByDevice\"]:\n",
    "                            user_list.append({\n",
    "                                \"State\": state,\n",
    "                                \"Year\": int(year),\n",
    "                                \"Quarter\": int(file.strip(\".json\")),\n",
    "                                \"Brand\": brand_data[\"brand\"],\n",
    "                                \"User_Count\": brand_data[\"count\"],\n",
    "                                \"Percentage\": brand_data[\"percentage\"]\n",
    "                            })\n",
    "                except (TypeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "    return pd.DataFrame(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a999148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Extracting Aggregated Users...\")\n",
    "df_users = extract_aggregated_users(BASE_DIR)\n",
    "\n",
    "if not df_users.empty:\n",
    "    df_users.to_csv(\"phonepe_aggregated_users.csv\", index=False)\n",
    "    print(\"‚úÖ Saved as phonepe_aggregated_users.csv\")\n",
    "    print(f\"Rows Extracted: {len(df_users)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No user data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204f6c8",
   "metadata": {},
   "source": [
    "## üîπ Phase 3: District-Level Transaction Extraction\n",
    "\n",
    "This section extracts district-level transaction metrics from:\n",
    "\n",
    "`map/transaction/hover/country/india/state/`\n",
    "\n",
    "Fields extracted:\n",
    "\n",
    "- District  \n",
    "- Transaction Count  \n",
    "- Transaction Amount  \n",
    "- State  \n",
    "- Year  \n",
    "- Quarter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41160c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_district_map_transactions(base_dir):\n",
    "    path = base_dir / \"map/transaction/hover/country/india/state\"\n",
    "    data_list = []\n",
    "\n",
    "    if not path.exists():\n",
    "        print(f\"Path not found: {path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for state in os.listdir(path):\n",
    "        state_path = path / state\n",
    "\n",
    "        for year in os.listdir(state_path):\n",
    "            year_path = state_path / year\n",
    "\n",
    "            for file in os.listdir(year_path):\n",
    "                file_path = year_path / file\n",
    "\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                try:\n",
    "                    for item in data[\"data\"][\"hoverDataList\"]:\n",
    "                        data_list.append({\n",
    "                            \"State\": state,\n",
    "                            \"Year\": int(year),\n",
    "                            \"Quarter\": int(file.strip(\".json\")),\n",
    "                            \"District\": item[\"name\"],\n",
    "                            \"Transaction_Count\": item[\"metric\"][0][\"count\"],\n",
    "                            \"Transaction_Amount\": item[\"metric\"][0][\"amount\"]\n",
    "                        })\n",
    "                except (TypeError, KeyError):\n",
    "                    continue\n",
    "\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e1529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Extracting District-Level Data...\")\n",
    "df_districts = extract_district_map_transactions(BASE_DIR)\n",
    "\n",
    "if not df_districts.empty:\n",
    "    df_districts.to_csv(\"phonepe_district_map_transactions.csv\", index=False)\n",
    "    print(\"‚úÖ Saved as phonepe_district_map_transactions.csv\")\n",
    "    print(f\"Rows Extracted: {len(df_districts)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No district data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3673bd",
   "metadata": {},
   "source": [
    "## üßπ Phase 4: Data Cleaning & Standardization\n",
    "\n",
    "Standardization steps:\n",
    "\n",
    "- Convert state names to title case  \n",
    "- Replace hyphens with spaces  \n",
    "- Remove \"District\" suffix  \n",
    "- Trim whitespace  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0012332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state_names(df):\n",
    "    df[\"State\"] = df[\"State\"].str.replace(\"-\", \" \").str.title()\n",
    "    return df\n",
    "\n",
    "def clean_district_names(df):\n",
    "    df[\"District\"] = df[\"District\"].str.replace(\" District\", \"\", regex=False)\n",
    "    df[\"District\"] = df[\"District\"].str.strip().str.title()\n",
    "    return df\n",
    "\n",
    "df_transactions = clean_state_names(df_transactions)\n",
    "df_users = clean_state_names(df_users)\n",
    "df_districts = clean_state_names(df_districts)\n",
    "df_districts = clean_district_names(df_districts)\n",
    "\n",
    "df_transactions.to_csv(\"phonepe_aggregated_transactions.csv\", index=False)\n",
    "df_users.to_csv(\"phonepe_aggregated_users.csv\", index=False)\n",
    "df_districts.to_csv(\"phonepe_district_map_transactions.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Data cleaning completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fb3a3",
   "metadata": {},
   "source": [
    "## üöÄ ETL Pipeline Completed Successfully\n",
    "\n",
    "Generated structured datasets:\n",
    "\n",
    "- phonepe_aggregated_transactions.csv\n",
    "- phonepe_aggregated_users.csv\n",
    "- phonepe_district_map_transactions.csv\n",
    "\n",
    "These datasets are now ready for:\n",
    "\n",
    "- Star Schema Modeling  \n",
    "- DAX Calculations  \n",
    "- Shape Map Integration  \n",
    "- Forecasting  \n",
    "- Decomposition Tree Analysis  \n",
    "\n",
    "### üîó Next Step\n",
    "\n",
    "Import the generated CSV files into Power BI and apply DAX modeling as documented in:\n",
    "\n",
    "Scripts/DAX-Measures.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
